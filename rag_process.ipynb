{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db0ab4af-9053-4aba-a6fd-bb4c001dff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import section\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_ollama.llms import OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "525e9ad5-fe74-4071-95f8-e27f2a5eae22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pdf file loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load local pdf file exploding_kittens.pdf\n",
    "file_path_local='sample/exploding_kittens.pdf'\n",
    "loader = PDFPlumberLoader(file_path=file_path_local)\n",
    "document = loader.load()\n",
    "print(\"✅ Pdf file loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bee18fd-29fd-4f39-b368-6f45b0643a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data chunked successfully\n"
     ]
    }
   ],
   "source": [
    "# Chunking of data where chunk_size, chunk_overlap is configurble and defined as per data document & use case\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "data_chunks = text_splitter.split_documents(document)\n",
    "print(\"✅ Data chunked successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "223ec617-711c-4019-be45-582ba084467f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 25/25 [00:56<00:00,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data stored successfully in chroma db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Store chunks and embeddings received from ollama embedding model in chroma database\n",
    "# For this example Embedding model is nomic-embed-text\n",
    "Chroma.from_documents(data_chunks, OllamaEmbeddings(model=\"nomic-embed-text\",show_progress=True),persist_directory=\"chroma_store\", collection_name='local_rag')\n",
    "print(\"✅ Data stored successfully in chroma db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66f58681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents fetched from database : 5\n"
     ]
    }
   ],
   "source": [
    "local_model = \"deepseek-r1:1.5b\"\n",
    "embedding_model = \"nomic-embed-text\"\n",
    "\n",
    "#load the chroma vector database created in previous step using same embeddings model.\n",
    "vector_db = Chroma(persist_directory=\"chroma_store\", embedding_function=OllamaEmbeddings(model=embedding_model), collection_name=\"local_rag\")\n",
    "question = \"What are Defuse Cards?\"\n",
    "docs = vector_db.similarity_search(question, k=5)\n",
    "print(\"Documents fetched from database : \"+str(len(docs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6281a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out what the answer is for the question \"What are Defuse Cards?\" based on the given context. Let me read through the text again carefully.\n",
      "\n",
      "Hmm, the context describes a card scenario in a game. It mentions something about Defuse Cards being the most powerful cards, used to stop an Exploding Kitten from dying. The description says that when someone's turn comes and they have a Defuse Card, if their card is \"dead\" (as in it just explodes but doesn't explode completely), then another player can end your turn by drawing a card.\n",
      "\n",
      "Wait, actually, I think the text is explaining how to play the game, specifically about how to save oneself from an Exploding Kitten. So, the Defuse Card seems to be used to stop an explosion. It's not that you're saving others; it's that you're preventing another player from ending your turn.\n",
      "\n",
      "So putting this together, Defuse Cards are cards that allow players to stop or end their turn by exploding a kitten. They prevent other players from doing the same and thus \"saving\" them.\n",
      "</think>\n",
      "\n",
      "Defuse Cards are powerful cards used in the game to prevent others from ending your turn. When your card is \"dead,\" meaning it only explodes temporarily, another player can end your action by drawing a card, effectively saving you. So, Defuse Cards allow you to stop explosions and let others finish their turns.\n",
      "\n",
      "Answer: Defuse Cards are cards that allow players to stop explosions by preventing others from ending their turn.\n",
      "✅ All steps completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Join all the documents fetched from database\n",
    "context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "# Create a RAG prompt in below format\n",
    "conversation_prompt = f\"\"\"Answer the question based only on the following context. Be concise. If you cannot find the answer in the context, say \"I cannot answer this based on the provided context.\"\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Call ollama chat api to generate the response from provided context\n",
    "LANGUAGE_MODEL = OllamaLLM(model=\"deepseek-r1:1.5b\")\n",
    "response = LANGUAGE_MODEL.invoke(conversation_prompt)\n",
    "print(response)\n",
    "print(\"✅ All steps completed successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
